#!/usr/bin/env python3
"""
Ph√¢n t√≠ch chi ti·∫øt ch·∫•t l∆∞·ª£ng d·ªãch trong output
"""
import os
import zipfile
from pathlib import Path
import re
from collections import defaultdict
import langdetect
from langdetect import detect
from langdetect.lang_detect_exception import LangDetectException

class TranslationQualityAnalyzer:
    def __init__(self):
        self.language_stats = defaultdict(int)
        self.translation_issues = []
        self.duplicated_content = defaultdict(list)
        
    def detect_language(self, text):
        """Ph√°t hi·ªán ng√¥n ng·ªØ c·ªßa text"""
        try:
            if len(text.strip()) < 10:
                return "unknown"
            # Ch·ªâ l·∫•y ph·∫ßn value sau d·∫•u =
            if '=' in text:
                value = text.split('=', 1)[1].strip()
                if len(value) < 5:
                    return "short"
                return detect(value)
            return detect(text)
        except (LangDetectException, Exception):
            return "unknown"
    
    def analyze_cfg_content(self, content, filename):
        """Ph√¢n t√≠ch n·ªôi dung file .cfg"""
        lines = content.split('\n')
        results = {
            'total_lines': len(lines),
            'translation_lines': 0,
            'languages': defaultdict(int),
            'issues': [],
            'samples': []
        }
        
        translation_lines = []
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            if not line or line.startswith('#') or line.startswith('['):
                continue
                
            if '=' in line:
                key, value = line.split('=', 1)
                key = key.strip()
                value = value.strip()
                
                if len(value) > 0:
                    results['translation_lines'] += 1
                    translation_lines.append((line_num, key, value))
                    
                    # Ph√°t hi·ªán ng√¥n ng·ªØ
                    lang = self.detect_language(value)
                    results['languages'][lang] += 1
                    
                    # Ki·ªÉm tra c√°c v·∫•n ƒë·ªÅ
                    issues = self.check_translation_issues(key, value, line_num)
                    results['issues'].extend(issues)
                    
                    # L∆∞u m·∫´u
                    if len(results['samples']) < 10:
                        results['samples'].append({
                            'line': line_num,
                            'key': key,
                            'value': value,
                            'language': lang
                        })
        
        return results
    
    def check_translation_issues(self, key, value, line_num):
        """Ki·ªÉm tra c√°c v·∫•n ƒë·ªÅ trong d·ªãch"""
        issues = []
        
        # 1. Ki·ªÉm tra mixed languages (ti·∫øng Vi·ªát l·∫´n ti·∫øng kh√°c)
        if self.has_mixed_languages(value):
            issues.append({
                'type': 'mixed_language',
                'line': line_num,
                'key': key,
                'value': value,
                'description': 'Mixed languages in translation'
            })
        
        # 2. Ki·ªÉm tra kh√¥ng d·ªãch (v·∫´n l√† ti·∫øng Anh)
        try:
            detected_lang = detect(value)
            if detected_lang == 'en' and len(value) > 10:
                issues.append({
                    'type': 'not_translated',
                    'line': line_num,
                    'key': key,
                    'value': value,
                    'description': 'Still in English'
                })
        except:
            pass
        
        # 3. Ki·ªÉm tra d·ªãch sai (c√≥ k√Ω t·ª± l·∫°)
        if self.has_weird_characters(value):
            issues.append({
                'type': 'weird_characters',
                'line': line_num,
                'key': key,
                'value': value,
                'description': 'Contains unusual characters'
            })
        
        return issues
    
    def has_mixed_languages(self, text):
        """Ki·ªÉm tra text c√≥ tr·ªôn l·∫´n ng√¥n ng·ªØ kh√¥ng"""
        # Ki·ªÉm tra c√≥ k√Ω t·ª± Vi·ªát Nam v√† Latin c√πng l√∫c
        has_vietnamese = bool(re.search(r'[√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒëƒê]', text))
        has_latin = bool(re.search(r'[a-zA-Z]', text))
        
        if has_vietnamese and has_latin:
            # N·∫øu c√≥ c·∫£ ti·∫øng Vi·ªát v√† Latin, ki·ªÉm tra xem c√≥ ph·∫£i mixed kh√¥ng
            vietnamese_words = len(re.findall(r'[√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒëƒê]\w*', text))
            total_words = len(text.split())
            return vietnamese_words < total_words * 0.7  # N·∫øu √≠t h∆°n 70% t·ª´ Vi·ªát
        
        return False
    
    def has_weird_characters(self, text):
        """Ki·ªÉm tra k√Ω t·ª± l·∫°"""
        # Ki·ªÉm tra k√Ω t·ª± kh√¥ng ph·∫£i ti·∫øng Vi·ªát, Anh, s·ªë, ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát th√¥ng th∆∞·ªùng
        weird_chars = re.findall(r'[^\w\s\-\.\,\!\?\(\)\[\]√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒëƒêa-zA-Z0-9]', text)
        return len(weird_chars) > 0
    
    def analyze_output_directory(self, output_dir="output"):
        """Ph√¢n t√≠ch to√†n b·ªô output directory"""
        output_path = Path(output_dir)
        if not output_path.exists():
            print(f"‚ùå Directory {output_dir} kh√¥ng t·ªìn t·∫°i!")
            return
        
        zip_files = list(output_path.glob("*.zip"))
        if not zip_files:
            print(f"‚ùå Kh√¥ng c√≥ file zip n√†o trong {output_dir}!")
            return
        
        print(f"üîç PH√ÇN T√çCH CH·∫§T L∆Ø·ª¢NG D·ªäCH")
        print("=" * 60)
        
        all_results = {}
        total_files = 0
        total_issues = 0
        language_summary = defaultdict(int)
        
        for zip_file in zip_files:
            print(f"\nüì¶ Analyzing: {zip_file.name}")
            
            try:
                with zipfile.ZipFile(zip_file, 'r') as zipf:
                    cfg_files = [f for f in zipf.namelist() if f.endswith('.cfg')]
                    print(f"  üìÑ Found {len(cfg_files)} .cfg files")
                    
                    file_results = {}
                    
                    for cfg_file in cfg_files:
                        try:
                            content = zipf.read(cfg_file).decode('utf-8')
                            result = self.analyze_cfg_content(content, cfg_file)
                            file_results[cfg_file] = result
                            total_files += 1
                            total_issues += len(result['issues'])
                            
                            # C·∫≠p nh·∫≠t th·ªëng k√™ ng√¥n ng·ªØ
                            for lang, count in result['languages'].items():
                                language_summary[lang] += count
                            
                        except Exception as e:
                            print(f"    ‚ùå Error reading {cfg_file}: {e}")
                    
                    all_results[zip_file.name] = file_results
                    
            except Exception as e:
                print(f"  ‚ùå Error processing zip: {e}")
        
        # B√°o c√°o t·ªïng k·∫øt
        self.generate_summary_report(all_results, total_files, total_issues, language_summary)
        
        # B√°o c√°o chi ti·∫øt c√°c v·∫•n ƒë·ªÅ
        self.generate_detailed_issues_report(all_results)
        
        return all_results
    
    def generate_summary_report(self, all_results, total_files, total_issues, language_summary):
        """T·∫°o b√°o c√°o t·ªïng k·∫øt"""
        print(f"\nüìä B√ÅOM C√ÅO T·ªîNG K·∫æT")
        print("=" * 40)
        print(f"‚Ä¢ T·ªïng s·ªë .cfg files: {total_files}")
        print(f"‚Ä¢ T·ªïng s·ªë v·∫•n ƒë·ªÅ: {total_issues}")
        
        print(f"\nüåç Th·ªëng k√™ ng√¥n ng·ªØ ph√°t hi·ªán:")
        for lang, count in sorted(language_summary.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / sum(language_summary.values())) * 100
            flag = self.get_language_flag(lang)
            print(f"  {flag} {lang}: {count} ({percentage:.1f}%)")
    
    def get_language_flag(self, lang):
        """L·∫•y flag cho ng√¥n ng·ªØ"""
        flags = {
            'vi': 'üáªüá≥',
            'en': 'üá∫üá∏', 
            'cs': 'üá®üáø',
            'de': 'üá©üá™',
            'fr': 'üá´üá∑',
            'unknown': '‚ùì',
            'short': 'üìè'
        }
        return flags.get(lang, '‚ùì')
    
    def generate_detailed_issues_report(self, all_results):
        """T·∫°o b√°o c√°o chi ti·∫øt c√°c v·∫•n ƒë·ªÅ"""
        print(f"\n‚ö†Ô∏è CHI TI·∫æT C√ÅC V·∫§N ƒê·ªÄ")
        print("=" * 40)
        
        issue_types = defaultdict(list)
        
        for zip_name, file_results in all_results.items():
            for cfg_file, result in file_results.items():
                for issue in result['issues']:
                    issue['zip'] = zip_name
                    issue['file'] = cfg_file
                    issue_types[issue['type']].append(issue)
        
        for issue_type, issues in issue_types.items():
            print(f"\nüö® {issue_type.upper()}: {len(issues)} cases")
            
            # Hi·ªÉn th·ªã m·ªôt s·ªë v√≠ d·ª•
            for i, issue in enumerate(issues[:5]):
                print(f"  {i+1}. {issue['file']}:{issue['line']}")
                print(f"     Key: {issue['key']}")
                print(f"     Value: {issue['value'][:100]}...")
                print(f"     Issue: {issue['description']}")
                print()
            
            if len(issues) > 5:
                print(f"     ... v√† {len(issues) - 5} cases kh√°c")

def main():
    analyzer = TranslationQualityAnalyzer()
    analyzer.analyze_output_directory()

if __name__ == "__main__":
    main()

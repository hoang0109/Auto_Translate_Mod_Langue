#!/usr/bin/env python3
"""
Large Scale Translation Test
Test v·ªõi 10 mod kh√°c nhau s·ª≠ d·ª•ng d·ªãch mi·ªÖn ph√≠ (Google Translate ho·∫∑c mock advanced)
"""
import os
import shutil
import sys
import json
import zipfile
import time
import hashlib
from pathlib import Path
import tempfile
from datetime import datetime
from collections import defaultdict

# Add current directory to path  
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from mod_translate_core import find_locale_files, parse_cfg_lines, read_cfg_file

# Free translation alternatives
try:
    from googletrans import Translator as GoogleTranslator
    GOOGLE_AVAILABLE = True
except ImportError:
    GOOGLE_AVAILABLE = False
    print("‚ö†Ô∏è googletrans not available, using advanced mock translation")

class FreeTranslationEngine:
    """Engine d·ªãch mi·ªÖn ph√≠ v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p"""
    
    def __init__(self):
        self.google_translator = GoogleTranslator() if GOOGLE_AVAILABLE else None
        self.translation_cache = {}
        
        # Vietnamese translation dictionary
        self.vietnamese_dict = {
            # Common game terms
            "speed": "t·ªëc ƒë·ªô",
            "belt": "bƒÉng t·∫£i", 
            "conveyor": "bƒÉng chuy·ªÅn",
            "multiplier": "h·ªá s·ªë nh√¢n",
            "setting": "c√†i ƒë·∫∑t",
            "language": "ng√¥n ng·ªØ",
            "target": "m·ª•c ti√™u",
            "size": "k√≠ch th∆∞·ªõc",
            "big": "l·ªõn",
            "small": "nh·ªè",
            "bag": "t√∫i",
            "inventory": "kho ƒë·ªì",
            "item": "v·∫≠t ph·∫©m",
            "recipe": "c√¥ng th·ª©c",
            "technology": "c√¥ng ngh·ªá",
            "research": "nghi√™n c·ª©u",
            "entity": "th·ª±c th·ªÉ",
            "fluid": "ch·∫•t l·ªèng",
            "tile": "√¥ ƒë·∫•t",
            "signal": "t√≠n hi·ªáu",
            "virtual": "·∫£o",
            "translate": "d·ªãch",
            "batch": "l√¥",
            "request": "y√™u c·∫ßu",
            "how many": "bao nhi√™u",
            "per": "m·ªói",
            "electric": "ƒëi·ªán",
            "pole": "c·ªôt",
            "range": "ph·∫°m vi",
            "machine": "m√°y m√≥c",
            "mining": "khai th√°c",
            "drone": "m√°y bay kh√¥ng ng∆∞·ªùi l√°i",
            "calculator": "m√°y t√≠nh",
            "rate": "t·ª∑ l·ªá",
            "hero": "anh h√πng",
            "turret": "th√°p ph√°o",
            "redux": "c·∫£i ti·∫øn",
            "monster": "qu√°i v·∫≠t",
            "biter": "c√¥n tr√πng c·∫Øn",
            "cold": "l·∫°nh",
            "frost": "bƒÉng gi√°",
            "explosive": "n·ªï",
            "armoured": "b·ªçc th√©p",
            "armor": "gi√°p",
            "bot": "robot",
            "start": "b·∫Øt ƒë·∫ßu",
            "mega": "si√™u",
            "gun": "s√∫ng",
            "equipment": "trang b·ªã",
            "burner": "ƒë·ªët nhi√™n li·ªáu",
            "alien": "ng∆∞·ªùi ngo√†i h√†nh tinh",
            "chaos": "h·ªón lo·∫°n",
            "modpack": "g√≥i mod",
            "enemy": "k·∫ª th√π",
            "arachnid": "nh·ªán",
            "stack": "ch·ªìng",
            "infinite": "v√¥ h·∫°n",
            "battery": "pin",
            "powered": "ƒë∆∞·ª£c cung c·∫•p ƒëi·ªán",
            "delta": "delta",
            # Common interface terms
            "name": "t√™n",
            "description": "m√¥ t·∫£", 
            "mod": "mod",
            "category": "danh m·ª•c",
            "group": "nh√≥m",
            "subgroup": "nh√≥m con",
            "order": "th·ª© t·ª±",
            "enabled": "b·∫≠t",
            "disabled": "t·∫Øt",
            "default": "m·∫∑c ƒë·ªãnh",
            "value": "gi√° tr·ªã",
            "option": "t√πy ch·ªçn",
            "tooltip": "ch√∫ th√≠ch",
            "label": "nh√£n"
        }
    
    def translate_with_google(self, text, target_lang='vi'):
        """D·ªãch b·∫±ng Google Translate (n·∫øu c√≥)"""
        if not self.google_translator:
            return None
        
        try:
            # Check cache first
            cache_key = f"{text}_{target_lang}"
            if cache_key in self.translation_cache:
                return self.translation_cache[cache_key]
            
            result = self.google_translator.translate(text, dest=target_lang)
            translated = result.text
            
            # Cache result
            self.translation_cache[cache_key] = translated
            return translated
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è Google Translate error: {e}")
            return None
    
    def advanced_mock_translate(self, text):
        """Mock translation n√¢ng cao v·ªõi AI-like logic"""
        original_text = text
        translated = text.lower()
        
        # Apply dictionary replacements
        for en_term, vi_term in self.vietnamese_dict.items():
            translated = translated.replace(en_term, vi_term)
        
        # Handle common patterns
        if "how many" in original_text.lower():
            translated = translated.replace("how many", "bao nhi√™u")
        
        if " per " in original_text.lower():
            translated = translated.replace(" per ", " m·ªói ")
        
        if translated.startswith("translate ("):
            translated = translated.replace("translate (", "d·ªãch (").replace(")", ")")
        
        # Capitalize first letter if original was capitalized
        if original_text and original_text[0].isupper():
            translated = translated.capitalize()
        
        # If no changes made, add [VI] prefix
        if translated.lower() == original_text.lower():
            translated = f"[VI] {original_text}"
        
        return translated
    
    def translate_text(self, text, use_google=True):
        """Translate text using available methods"""
        if use_google and GOOGLE_AVAILABLE:
            result = self.translate_with_google(text)
            if result:
                return result
        
        # Fallback to advanced mock
        return self.advanced_mock_translate(text)
    
    def translate_batch(self, texts, use_google=True):
        """Batch translate multiple texts"""
        results = []
        for text in texts:
            translated = self.translate_text(text, use_google)
            results.append(translated)
            
            # Add small delay to avoid rate limiting
            if use_google and GOOGLE_AVAILABLE:
                time.sleep(0.1)
        
        return results

def select_test_mods():
    """Ch·ªçn 10 mod ƒë·ªÉ test t·ª´ analysis tr∆∞·ªõc"""
    mods_dir = r"C:\Users\Acer\AppData\Roaming\Factorio\mods"
    
    # Top 10 mod recommendations t·ª´ analysis tr∆∞·ªõc
    target_mods = [
        "Babelfish_2.0.0.zip",           # 11 strings, 0.04 MB
        "BigBags_1.0.37.zip",            # 23 strings, 0.07 MB  
        "BeltSpeedMultiplier_1.0.3.zip", # 1 string, 0.02 MB
        "ElectricPoleRangeMultiplier_1.0.3.zip", # 1 string, 0.01 MB
        "MachineSpeedMultiplier_1.1.1.zip",      # 8 strings, 0.02 MB
        "BobsStackSize_1.0.0.zip",       # 1 string, 0.03 MB
        "GunEquipment_0.0.22.zip",       # 6 strings, 0.28 MB
        "Mining_Drones_2.0.2.zip",       # 7 strings, 3.88 MB
        "MegaBotStart_2.0.2.zip",        # 4 strings, 0.68 MB
        "RateCalculator_3.3.7.zip"       # 66 strings, 0.09 MB
    ]
    
    available_mods = []
    for mod_file in target_mods:
        mod_path = os.path.join(mods_dir, mod_file)
        if os.path.exists(mod_path):
            available_mods.append(mod_path)
    
    print(f"üéØ Selected {len(available_mods)} mods for large scale test:")
    for i, mod_path in enumerate(available_mods, 1):
        size_mb = os.path.getsize(mod_path) / (1024 * 1024)
        print(f"  {i}. {os.path.basename(mod_path)} ({size_mb:.3f} MB)")
    
    return available_mods

def analyze_mod_for_translation(mod_path):
    """Ph√¢n t√≠ch chi ti·∫øt m·ªôt mod ƒë·ªÉ d·ªãch"""
    print(f"\nüîç Analyzing {os.path.basename(mod_path)}...")
    
    mod_info = {
        'path': mod_path,
        'name': os.path.basename(mod_path),
        'size_mb': round(os.path.getsize(mod_path) / (1024*1024), 3),
        'translatable_strings': 0,
        'locale_files': [],
        'translation_data': {},
        'analysis_time': 0,
        'error': None
    }
    
    start_time = time.time()
    
    try:
        # Get mod metadata
        with zipfile.ZipFile(mod_path, 'r') as zipf:
            info_files = [f for f in zipf.namelist() if f.endswith('info.json')]
            if info_files:
                with zipf.open(info_files[0]) as f:
                    info_data = json.load(f)
                    mod_info['mod_name'] = info_data.get('name', 'unknown')
                    mod_info['version'] = info_data.get('version', 'unknown')
                    mod_info['title'] = info_data.get('title', '')
        
        # Find and analyze locale files
        root_folder, locale_files = find_locale_files(mod_path)
        mod_info['locale_files'] = locale_files
        
        if locale_files:
            with zipfile.ZipFile(mod_path, 'r') as zipf:
                for locale_file in locale_files:
                    raw_content = read_cfg_file(zipf, locale_file)
                    key_vals, original_lines = parse_cfg_lines(raw_content)
                    
                    if key_vals:
                        file_data = {
                            'key_vals': key_vals,
                            'original_lines': original_lines,
                            'string_count': len(key_vals)
                        }
                        mod_info['translation_data'][locale_file] = file_data
                        mod_info['translatable_strings'] += len(key_vals)
        
        mod_info['analysis_time'] = time.time() - start_time
        
        print(f"  ‚úÖ {mod_info['mod_name']} v{mod_info['version']}")
        print(f"  üìä {mod_info['translatable_strings']} translatable strings")
        print(f"  üìÅ {len(locale_files)} locale files")
        print(f"  ‚è±Ô∏è Analysis time: {mod_info['analysis_time']:.2f}s")
        
        return mod_info
        
    except Exception as e:
        mod_info['error'] = str(e)
        print(f"  ‚ùå Error: {e}")
        return mod_info

def translate_mod_content_large_scale(mod_info, translator, use_google=True):
    """D·ªãch n·ªôi dung mod v·ªõi engine d·ªãch mi·ªÖn ph√≠"""
    print(f"\nüåê Translating {mod_info['mod_name']}...")
    
    if mod_info.get('error') or not mod_info['translation_data']:
        print("  ‚ö™ Skipping due to analysis error or no content")
        return None
    
    start_time = time.time()
    translation_results = {}
    total_translated = 0
    
    for locale_file, file_data in mod_info['translation_data'].items():
        print(f"  üìÑ Processing {os.path.basename(locale_file)}...")
        
        key_vals = file_data['key_vals']
        original_lines = file_data['original_lines']
        
        # Extract texts to translate
        texts_to_translate = [item['val'] for item in key_vals]
        
        if not texts_to_translate:
            continue
        
        # Batch translate
        try:
            translated_texts = translator.translate_batch(texts_to_translate, use_google)
            
            # Build translation pairs
            translation_pairs = []
            for i, item in enumerate(key_vals):
                translation_pairs.append({
                    'key': item['key'],
                    'original': item['val'],
                    'translated': translated_texts[i],
                    'line_index': item['index']
                })
            
            # Generate translated lines
            translated_lines = original_lines[:]
            for pair in translation_pairs:
                line_idx = pair['line_index']
                translated_lines[line_idx] = f"{pair['key']}={pair['translated']}\n"
            
            translation_results[os.path.basename(locale_file)] = {
                'original_lines': original_lines,
                'translated_lines': translated_lines,
                'translation_pairs': translation_pairs,
                'string_count': len(translation_pairs)
            }
            
            total_translated += len(translation_pairs)
            print(f"    ‚úÖ {len(translation_pairs)} strings translated")
            
        except Exception as e:
            print(f"    ‚ùå Translation error: {e}")
            continue
    
    translation_time = time.time() - start_time
    
    print(f"  ‚úÖ Total: {total_translated} strings translated in {translation_time:.2f}s")
    print(f"  ‚ö° Speed: {total_translated/translation_time:.1f} strings/second")
    
    return {
        'mod_info': mod_info,
        'translation_results': translation_results,
        'total_strings': total_translated,
        'translation_time': translation_time,
        'translation_speed': total_translated / translation_time if translation_time > 0 else 0
    }

def create_test_environment_large():
    """T·∫°o m√¥i tr∆∞·ªùng test cho quy m√¥ l·ªõn"""
    base_dir = "large_scale_test"
    test_dirs = [
        f"{base_dir}/input_mods",
        f"{base_dir}/translation_results",
        f"{base_dir}/performance_data",
        f"{base_dir}/logs",
        f"{base_dir}/cache"
    ]
    
    for dir_path in test_dirs:
        os.makedirs(dir_path, exist_ok=True)
    
    return base_dir

def save_translation_results(test_dir, results_list):
    """L∆∞u k·∫øt qu·∫£ d·ªãch v√† th·ªëng k√™ hi·ªáu nƒÉng"""
    results_dir = os.path.join(test_dir, "translation_results")
    performance_dir = os.path.join(test_dir, "performance_data")
    
    # Save individual translation results
    for i, result in enumerate(results_list):
        if result:
            mod_name = result['mod_info']['mod_name']
            
            # Save translation files
            mod_result_dir = os.path.join(results_dir, mod_name)
            os.makedirs(mod_result_dir, exist_ok=True)
            
            for filename, file_data in result['translation_results'].items():
                output_path = os.path.join(mod_result_dir, filename)
                with open(output_path, 'w', encoding='utf-8') as f:
                    for line in file_data['translated_lines']:
                        if not line.endswith('\n'):
                            f.write(line + '\n')
                        else:
                            f.write(line)
    
    # Save performance summary
    performance_summary = {
        'test_timestamp': datetime.now().isoformat(),
        'total_mods': len(results_list),
        'successful_mods': len([r for r in results_list if r]),
        'failed_mods': len([r for r in results_list if not r]),
        'total_strings': sum(r['total_strings'] for r in results_list if r),
        'total_translation_time': sum(r['translation_time'] for r in results_list if r),
        'average_speed': 0,
        'mod_details': []
    }
    
    # Calculate average speed
    successful_results = [r for r in results_list if r]
    if successful_results:
        performance_summary['average_speed'] = sum(r['translation_speed'] for r in successful_results) / len(successful_results)
    
    # Add mod details
    for result in results_list:
        if result:
            mod_detail = {
                'name': result['mod_info']['mod_name'],
                'size_mb': result['mod_info']['size_mb'],
                'strings': result['total_strings'],
                'time': result['translation_time'],
                'speed': result['translation_speed'],
                'files': len(result['translation_results'])
            }
            performance_summary['mod_details'].append(mod_detail)
    
    # Save performance data
    performance_file = os.path.join(performance_dir, f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    with open(performance_file, 'w', encoding='utf-8') as f:
        json.dump(performance_summary, f, indent=2, ensure_ascii=False)
    
    return performance_summary

def print_performance_report(performance_summary):
    """In b√°o c√°o hi·ªáu nƒÉng chi ti·∫øt"""
    print(f"\n{'='*80}")
    print("üìä LARGE SCALE TRANSLATION PERFORMANCE REPORT")
    print(f"{'='*80}")
    
    print(f"\nüìã OVERVIEW:")
    print(f"  ‚Ä¢ Test Time: {performance_summary['test_timestamp']}")
    print(f"  ‚Ä¢ Total Mods: {performance_summary['total_mods']}")
    print(f"  ‚Ä¢ Successful: {performance_summary['successful_mods']}")
    print(f"  ‚Ä¢ Failed: {performance_summary['failed_mods']}")
    print(f"  ‚Ä¢ Success Rate: {performance_summary['successful_mods']/performance_summary['total_mods']*100:.1f}%")
    
    print(f"\nüéØ TRANSLATION METRICS:")
    print(f"  ‚Ä¢ Total Strings Translated: {performance_summary['total_strings']:,}")
    print(f"  ‚Ä¢ Total Translation Time: {performance_summary['total_translation_time']:.2f} seconds")
    print(f"  ‚Ä¢ Average Speed: {performance_summary['average_speed']:.1f} strings/second")
    print(f"  ‚Ä¢ Throughput: {performance_summary['total_strings']/performance_summary['total_translation_time']:.1f} strings/second overall")
    
    print(f"\nüìà MOD BREAKDOWN:")
    print(f"{'Mod Name':<30} {'Strings':>8} {'Time':>8} {'Speed':>10} {'Files':>6}")
    print("-" * 70)
    
    for mod in performance_summary['mod_details']:
        print(f"{mod['name']:<30} {mod['strings']:>8} {mod['time']:>8.2f} {mod['speed']:>10.1f} {mod['files']:>6}")
    
    # Performance categories
    high_perf = [m for m in performance_summary['mod_details'] if m['speed'] > 50]
    medium_perf = [m for m in performance_summary['mod_details'] if 10 <= m['speed'] <= 50]
    low_perf = [m for m in performance_summary['mod_details'] if m['speed'] < 10]
    
    print(f"\n‚ö° PERFORMANCE CATEGORIES:")
    print(f"  ‚Ä¢ High Speed (>50 strings/s): {len(high_perf)} mods")
    print(f"  ‚Ä¢ Medium Speed (10-50 strings/s): {len(medium_perf)} mods")
    print(f"  ‚Ä¢ Low Speed (<10 strings/s): {len(low_perf)} mods")
    
    # Size vs Performance analysis
    small_mods = [m for m in performance_summary['mod_details'] if m['size_mb'] < 1.0]
    large_mods = [m for m in performance_summary['mod_details'] if m['size_mb'] >= 1.0]
    
    print(f"\nüì¶ SIZE VS PERFORMANCE:")
    if small_mods:
        avg_speed_small = sum(m['speed'] for m in small_mods) / len(small_mods)
        print(f"  ‚Ä¢ Small Mods (<1MB): {len(small_mods)} mods, avg speed {avg_speed_small:.1f} strings/s")
    if large_mods:
        avg_speed_large = sum(m['speed'] for m in large_mods) / len(large_mods)
        print(f"  ‚Ä¢ Large Mods (>=1MB): {len(large_mods)} mods, avg speed {avg_speed_large:.1f} strings/s")

def main():
    """Main function - Large Scale Translation Test"""
    print("üöÄ LARGE SCALE TRANSLATION TEST")
    print("Testing with 10 different mods using FREE translation")
    print("=" * 80)
    
    # Setup
    test_env = create_test_environment_large()
    translator = FreeTranslationEngine()
    
    print(f"\nüîß TRANSLATION ENGINE:")
    if GOOGLE_AVAILABLE:
        print("  ‚úÖ Google Translate API available")
        print("  üìù Will use Google Translate + Advanced Mock fallback")
        use_google = True
    else:
        print("  ‚ö™ Google Translate not available")
        print("  üìù Will use Advanced Mock Translation only")
        use_google = False
    
    # Select mods
    print(f"\nüì¶ SELECTING TEST MODS...")
    test_mods = select_test_mods()
    
    if len(test_mods) < 5:
        print(f"‚ö†Ô∏è Only {len(test_mods)} mods available, need at least 5 for meaningful test")
        return
    
    # Analyze all mods
    print(f"\nüîç ANALYZING {len(test_mods)} MODS...")
    mod_analyses = []
    total_analysis_time = 0
    
    for mod_path in test_mods:
        analysis = analyze_mod_for_translation(mod_path)
        mod_analyses.append(analysis)
        total_analysis_time += analysis.get('analysis_time', 0)
    
    print(f"\nüìä Analysis Complete: {total_analysis_time:.2f}s total")
    
    # Translation phase
    print(f"\nüåê TRANSLATION PHASE...")
    print("=" * 50)
    
    translation_results = []
    start_translation_time = time.time()
    
    for analysis in mod_analyses:
        if not analysis.get('error') and analysis['translatable_strings'] > 0:
            result = translate_mod_content_large_scale(analysis, translator, use_google)
            translation_results.append(result)
        else:
            print(f"\n‚ö™ Skipping {analysis['name']} - no translatable content")
            translation_results.append(None)
    
    total_translation_time = time.time() - start_translation_time
    
    # Save results and generate report
    print(f"\nüíæ SAVING RESULTS...")
    performance_summary = save_translation_results(test_env, translation_results)
    
    # Print comprehensive report
    print_performance_report(performance_summary)
    
    print(f"\nüéâ LARGE SCALE TEST COMPLETED!")
    print(f"üìÅ Results saved in: {test_env}")
    print(f"‚è±Ô∏è Total test time: {total_translation_time:.2f} seconds")

if __name__ == "__main__":
    main()
